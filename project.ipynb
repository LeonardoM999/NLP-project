{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/leonardo/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/cuda/__init__.py:758: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "import tqdm.notebook as tq\n",
    "from datasets import Dataset\n",
    "from typing import Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "\n",
    "device = \"cuda\" if cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load corpus\n",
    "\n",
    "data_path = Path(\"data/MELD_train_efr.json\")\n",
    "assert data_path.exists(), \"Data file is not present\"\n",
    "raw_df = pd.read_json(\n",
    "    data_path, dtype={\"speakers\": np.array}\n",
    ")  # , \"triggers\": np.array})\n",
    "EPISODE, SPEAKERS, EMOTIONS, UTTERANCES, TRIGGERS = raw_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>speakers</th>\n",
       "      <th>emotions</th>\n",
       "      <th>utterances</th>\n",
       "      <th>triggers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>utterance_0</td>\n",
       "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise]</td>\n",
       "      <td>[also I was the point person on my company's t...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>utterance_1</td>\n",
       "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
       "      <td>[also I was the point person on my company's t...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>utterance_2</td>\n",
       "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
       "      <td>[also I was the point person on my company's t...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>utterance_3</td>\n",
       "      <td>[Chandler, The Interviewer, Chandler, The Inte...</td>\n",
       "      <td>[neutral, neutral, neutral, neutral, surprise,...</td>\n",
       "      <td>[also I was the point person on my company's t...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>utterance_4</td>\n",
       "      <td>[Joey, Rachel, Joey, Rachel]</td>\n",
       "      <td>[surprise, sadness, surprise, fear]</td>\n",
       "      <td>[But then who? The waitress I went out with la...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       episode                                           speakers  \\\n",
       "0  utterance_0  [Chandler, The Interviewer, Chandler, The Inte...   \n",
       "1  utterance_1  [Chandler, The Interviewer, Chandler, The Inte...   \n",
       "2  utterance_2  [Chandler, The Interviewer, Chandler, The Inte...   \n",
       "3  utterance_3  [Chandler, The Interviewer, Chandler, The Inte...   \n",
       "4  utterance_4                       [Joey, Rachel, Joey, Rachel]   \n",
       "\n",
       "                                            emotions  \\\n",
       "0     [neutral, neutral, neutral, neutral, surprise]   \n",
       "1  [neutral, neutral, neutral, neutral, surprise,...   \n",
       "2  [neutral, neutral, neutral, neutral, surprise,...   \n",
       "3  [neutral, neutral, neutral, neutral, surprise,...   \n",
       "4                [surprise, sadness, surprise, fear]   \n",
       "\n",
       "                                          utterances  \\\n",
       "0  [also I was the point person on my company's t...   \n",
       "1  [also I was the point person on my company's t...   \n",
       "2  [also I was the point person on my company's t...   \n",
       "3  [also I was the point person on my company's t...   \n",
       "4  [But then who? The waitress I went out with la...   \n",
       "\n",
       "                                            triggers  \n",
       "0                          [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "1                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4                               [0.0, 0.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>speakers</th>\n",
       "      <th>emotions</th>\n",
       "      <th>utterances</th>\n",
       "      <th>triggers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4000</td>\n",
       "      <td>3350</td>\n",
       "      <td>3427</td>\n",
       "      <td>3998</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>utterance_0</td>\n",
       "      <td>[Monica, Chandler, Monica]</td>\n",
       "      <td>[neutral, neutral, joy]</td>\n",
       "      <td>[Happy?! Is that what I'm supposed to be Vic? ...</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            episode                    speakers                 emotions  \\\n",
       "count          4000                        4000                     4000   \n",
       "unique         4000                        3350                     3427   \n",
       "top     utterance_0  [Monica, Chandler, Monica]  [neutral, neutral, joy]   \n",
       "freq              1                          15                       30   \n",
       "\n",
       "                                               utterances         triggers  \n",
       "count                                                4000             4000  \n",
       "unique                                               3998              523  \n",
       "top     [Happy?! Is that what I'm supposed to be Vic? ...  [0.0, 1.0, 0.0]  \n",
       "freq                                                    2              191  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups: 832\n",
      "Avg group len: 4.8\n",
      "Longest group: 16\n",
      "Episodes not in a group: 128\n"
     ]
    }
   ],
   "source": [
    "### Look for how many groups of episodes with the same first utterance there are and their lenghts\n",
    "\n",
    "raw_df.sort_values(by=UTTERANCES, inplace=True)\n",
    "groups = np.zeros((850,), dtype=int)\n",
    "\n",
    "index = 0\n",
    "count = 1\n",
    "for i in range(1, len(raw_df[UTTERANCES])):\n",
    "    if raw_df[UTTERANCES][i][0] == raw_df[UTTERANCES][i - 1][0]:\n",
    "        ### still in the same group\n",
    "        count += 1\n",
    "    else:\n",
    "        ### found new group\n",
    "        groups[index] = count\n",
    "        index += 1\n",
    "        count = 1\n",
    "\n",
    "groups = groups[groups != 0]\n",
    "\n",
    "print(f\"Number of groups: {len(groups)}\")\n",
    "print(f\"Avg group len: {np.average(groups):.1f}\")\n",
    "print(f\"Longest group: {np.max(groups)}\")\n",
    "print(f\"Episodes not in a group: {groups[groups == 1].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of number of speakers:\n",
      "1 speakers:  214\n",
      "2 speakers:  2105\n",
      "3 speakers:  1030\n",
      "4 speakers:  405\n",
      "5 speakers:  161\n",
      "6 speakers:  74\n",
      "7 speakers:  10\n",
      "8 speakers:  1\n"
     ]
    }
   ],
   "source": [
    "### Count how many speakers there are in each episode\n",
    "\n",
    "speakers_count = raw_df[SPEAKERS].apply(lambda arr: np.unique(arr).shape[0]).to_numpy()\n",
    "min_sp = np.min(speakers_count)\n",
    "max_sp = np.max(speakers_count)\n",
    "print(\"Distribution of number of speakers:\")\n",
    "for count in range(min_sp, max_sp + 1):\n",
    "    print(f\"{count} speakers:  {np.sum(speakers_count == count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes values:\n",
      "{'neutral': 15263, 'joy': 6317, 'surprise': 4645, 'anger': 3964, 'sadness': 2648, 'fear': 1114, 'disgust': 1049}\n"
     ]
    }
   ],
   "source": [
    "### Class imbalance check\n",
    "classes_count = {}\n",
    "for emotions in raw_df[\"emotions\"]:\n",
    "    for emotion in emotions:\n",
    "        if emotion in classes_count:\n",
    "            classes_count[emotion] += 1\n",
    "        else:\n",
    "            classes_count[emotion] = 1\n",
    "\n",
    "### then we sort the dictionary by occurences\n",
    "emotions_dict = {\n",
    "    k: v\n",
    "    for k, v in sorted(classes_count.items(), key=lambda item: item[1], reverse=True)\n",
    "}\n",
    "print(\"Classes values:\")\n",
    "print(emotions_dict)\n",
    "\n",
    "### Classes counts are not balanced: the use of weights is recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop not useful column\n",
    "\n",
    "raw_df.drop(columns=[SPEAKERS], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove Nones from the triggers\n",
    "\n",
    "raw_df[TRIGGERS] = raw_df[TRIGGERS].apply(\n",
    "    lambda trig_seq: np.array([0.0 if t is None else t for t in trig_seq])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>emotions</th>\n",
       "      <th>utterances</th>\n",
       "      <th>triggers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>episode_1061</td>\n",
       "      <td>[joy, neutral, surprise]</td>\n",
       "      <td>[\"Happy birthday to you!\", You're paying for t...</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>episode_1062</td>\n",
       "      <td>[joy, neutral, surprise, surprise]</td>\n",
       "      <td>[\"Happy birthday to you!\", You're paying for t...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>episode_1063</td>\n",
       "      <td>[joy, neutral, surprise, surprise, neutral]</td>\n",
       "      <td>[\"Happy birthday to you!\", You're paying for t...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>episode_1064</td>\n",
       "      <td>[joy, neutral, surprise, surprise, neutral, ne...</td>\n",
       "      <td>[\"Happy birthday to you!\", You're paying for t...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>episode_1065</td>\n",
       "      <td>[joy, neutral, surprise, surprise, neutral, ne...</td>\n",
       "      <td>[\"Happy birthday to you!\", You're paying for t...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           episode                                           emotions  \\\n",
       "1061  episode_1061                           [joy, neutral, surprise]   \n",
       "1062  episode_1062                 [joy, neutral, surprise, surprise]   \n",
       "1063  episode_1063        [joy, neutral, surprise, surprise, neutral]   \n",
       "1064  episode_1064  [joy, neutral, surprise, surprise, neutral, ne...   \n",
       "1065  episode_1065  [joy, neutral, surprise, surprise, neutral, ne...   \n",
       "\n",
       "                                             utterances  \\\n",
       "1061  [\"Happy birthday to you!\", You're paying for t...   \n",
       "1062  [\"Happy birthday to you!\", You're paying for t...   \n",
       "1063  [\"Happy birthday to you!\", You're paying for t...   \n",
       "1064  [\"Happy birthday to you!\", You're paying for t...   \n",
       "1065  [\"Happy birthday to you!\", You're paying for t...   \n",
       "\n",
       "                                 triggers  \n",
       "1061                      [0.0, 1.0, 0.0]  \n",
       "1062                 [0.0, 0.0, 1.0, 0.0]  \n",
       "1063            [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "1064       [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "1065  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Change column \"episode\" from utterance_xyz to episode_xyz\n",
    "for i in range(len(raw_df)):\n",
    "    raw_df[EPISODE][i] = f\"episode_{raw_df[EPISODE][i][10:]}\"\n",
    "\n",
    "clean_df = raw_df\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If an episode contains the same utterances of the previous and a few more then the triggers from the previous episode are replicated in the current episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"{raw_df[TRIGGERS][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replicate triggers\n",
    "\n",
    "count = 0\n",
    "for i in range(1, len(clean_df)):\n",
    "    is_continuation = np.all(\n",
    "        [u in clean_df[UTTERANCES][i] for u in clean_df[UTTERANCES][i - 1]]\n",
    "    )\n",
    "    if is_continuation:\n",
    "        count += 1\n",
    "        for k, t in enumerate(clean_df[TRIGGERS][i - 1]):\n",
    "            clean_df[TRIGGERS][i][k] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[0. 1. 0. 1.]\n",
      "[0. 1. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"{raw_df[TRIGGERS][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Val Test split: 80/10/10\n",
    "\n",
    "\n",
    "def split_data(\n",
    "    df: pd.DataFrame, seed: int = 42\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    df_train, df_test = train_test_split(\n",
    "        df, test_size=0.2, train_size=0.8, random_state=seed\n",
    "    )\n",
    "\n",
    "    df_val, df_test = train_test_split(\n",
    "        df_test, test_size=0.5, train_size=0.5, random_state=seed\n",
    "    )\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train len: 3200\n",
      "df_val len: 400\n",
      "df_test len: 400\n"
     ]
    }
   ],
   "source": [
    "### Check\n",
    "df_train_t, df_val_t, df_test_t = split_data(clean_df)\n",
    "print(f\"df_train len: {len(df_train_t)}\")\n",
    "print(f\"df_val len: {len(df_val_t)}\")\n",
    "print(f\"df_test len: {len(df_test_t)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explode the dataframe: <br>\n",
    "each rows contains: previous utterance, target utterance, next utterance (for context). <br>\n",
    "Except for the first and lat utterance of each episode that have no previous and next utterance, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_add_context_old(df: pd.DataFrame, ctxt_win_len: int = 1) -> pd.DataFrame:\n",
    "    # TODO ok che context_window sia il numero di utt future == numero utt passate invece che la len di tutta la window?\n",
    "\n",
    "    ### Flatten the lists of utterances,triggers,emotions into new rows of the dataframe\n",
    "    exploded_df = df.explode([UTTERANCES, TRIGGERS, EMOTIONS], ignore_index=True)\n",
    "    exploded_df.rename(columns={UTTERANCES: \"current\"}, inplace=True)\n",
    "    exploded_df.head(10)\n",
    "\n",
    "    ### Pair shifted columns of utterances to the exploded df to make previous and next\n",
    "    for i in range(1, ctxt_win_len + 1):\n",
    "        padding_cells = pd.Series([\" \" for _ in range(i)])\n",
    "\n",
    "        previous_col = pd.concat(\n",
    "            (padding_cells, exploded_df[\"current\"][:-i]), copy=False\n",
    "        ).to_list()\n",
    "        exploded_df.insert(loc=2, column=f\"previous_-{i}\", value=previous_col)\n",
    "\n",
    "        next_col = pd.concat(\n",
    "            (exploded_df[\"current\"][i:], padding_cells), copy=False\n",
    "        ).to_list()\n",
    "        exploded_df.insert(loc=2 + 2 * i, column=f\"next_{i}\", value=next_col)\n",
    "\n",
    "    ### Remove the previous of the first utterance and the next of the last utterance of each episode\n",
    "    for i in range(1, len(exploded_df) - 1):\n",
    "        for j in range(1, ctxt_win_len + 1):\n",
    "            if exploded_df[EPISODE][i] != exploded_df[EPISODE][i - 1]:\n",
    "                exploded_df[f\"next_{j}\"][i - j] = \" \"\n",
    "                exploded_df[f\"previous_-{j}\"][i] = \" \"\n",
    "\n",
    "    exploded_df.sort_values(by=EPISODE, inplace=True)\n",
    "    # TODO sortare prima su episode poi sull'indice\n",
    "    return exploded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': array([1., 0., 0., 0., 0., 0., 0.]), 'disgust': array([0., 1., 0., 0., 0., 0., 0.]), 'fear': array([0., 0., 1., 0., 0., 0., 0.]), 'joy': array([0., 0., 0., 1., 0., 0., 0.]), 'neutral': array([0., 0., 0., 0., 1., 0., 0.]), 'sadness': array([0., 0., 0., 0., 0., 1., 0.]), 'surprise': array([0., 0., 0., 0., 0., 0., 1.])}\n"
     ]
    }
   ],
   "source": [
    "all_emotions = df_train_t[EMOTIONS].explode().to_numpy()\n",
    "uniq_emotions = np.sort(np.unique(all_emotions))\n",
    "# uniq_emotions = [\"neutral\", \"joy\", \"surprise\", \"anger\", \"sadness\", \"disgust\", \"fear\"]\n",
    "one_hot = np.identity(len(uniq_emotions))\n",
    "emotion_mapping = {e: one_hot[i] for i, e in enumerate(uniq_emotions)}\n",
    "print(emotion_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A separator B separator C'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO remove\n",
    "\" separator \".join([\"A\", \"B\", \"C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_add_context(df: pd.DataFrame, ctxt_win_len: int = 1) -> pd.DataFrame:\n",
    "\n",
    "    new_df = {\"emotion\": [], \"trigger\": [], \"hist_curr\": [], \"next\": [], \"episode\": []}\n",
    "\n",
    "    utt_separator = \" \"  # TODO va bene ' ' come separatore?\n",
    "    ### for each original row\n",
    "    for _, row in df.iterrows():\n",
    "        ### create as many new rows as utterances in the original row\n",
    "        for utt_idx, (emo, trig) in enumerate(zip(row[EMOTIONS], row[TRIGGERS])):\n",
    "            # new_df[\"emotion\"].append(emotion_mapping[emo]) # TODO not possible here: baselines do not like it\n",
    "            new_df[\"emotion\"].append(emo)\n",
    "            new_df[\"trigger\"].append(trig)\n",
    "            new_df[\"episode\"].append(row[\"episode\"])\n",
    "\n",
    "            ### previous utterances + current (same way triggers are defined)\n",
    "            start_hist = np.max((0, utt_idx - ctxt_win_len))\n",
    "            curr_incl = utt_idx + 1\n",
    "            hist_curr = utt_separator.join(row[UTTERANCES][start_hist:curr_incl])\n",
    "            new_df[\"hist_curr\"].append(hist_curr)\n",
    "\n",
    "            ### next utterances\n",
    "            curr_excl = utt_idx + 1\n",
    "            last_next_excl = utt_idx + ctxt_win_len + 1\n",
    "            next = utt_separator.join(row[UTTERANCES][curr_excl:last_next_excl])\n",
    "            new_df[\"next\"].append(next)\n",
    "\n",
    "    new_df = pd.DataFrame(new_df)\n",
    "    ### important: the new_df still has utterances grouped by episode (to make the metrics work), otherwise we sort\n",
    "    new_df.sort_values(by=EPISODE, inplace=True)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = explode_add_context(df_train_t, 2)\n",
    "df_val = explode_add_context(df_val_t, 2)\n",
    "df_test = explode_add_context(df_test_t, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>trigger</th>\n",
       "      <th>hist_curr</th>\n",
       "      <th>next</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>surprise</td>\n",
       "      <td>0.0</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td></td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>So let's talk a little bit about your duties. ...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24390</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24389</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24391</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>So let's talk a little bit about your duties. ...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24395</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>My duties?  All right. Now you'll be heading a...</td>\n",
       "      <td></td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24392</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>My duties?  All right. Now you'll be heading a...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        emotion  trigger                                          hist_curr  \\\n",
       "864     neutral      0.0  also I was the point person on my company's tr...   \n",
       "868    surprise      0.0  That I did. That I did. So let's talk a little...   \n",
       "867     neutral      1.0  You must've had your hands full. That I did. T...   \n",
       "866     neutral      0.0  also I was the point person on my company's tr...   \n",
       "865     neutral      0.0  also I was the point person on my company's tr...   \n",
       "24390   neutral      0.0  also I was the point person on my company's tr...   \n",
       "24389   neutral      0.0  also I was the point person on my company's tr...   \n",
       "24391   neutral      0.0  also I was the point person on my company's tr...   \n",
       "24395   neutral      0.0  My duties?  All right. Now you'll be heading a...   \n",
       "24392   neutral      1.0  You must've had your hands full. That I did. T...   \n",
       "\n",
       "                                                    next    episode  \n",
       "864    You must've had your hands full. That I did. T...  episode_0  \n",
       "868                                                       episode_0  \n",
       "867                               My duties?  All right.  episode_0  \n",
       "866    So let's talk a little bit about your duties. ...  episode_0  \n",
       "865    That I did. That I did. So let's talk a little...  episode_0  \n",
       "24390  That I did. That I did. So let's talk a little...  episode_1  \n",
       "24389  You must've had your hands full. That I did. T...  episode_1  \n",
       "24391  So let's talk a little bit about your duties. ...  episode_1  \n",
       "24395                                                     episode_1  \n",
       "24392  My duties?  All right. Now you'll be heading a...  episode_1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just wanna check my horoscope, see if it was right. Oh my God. Phoebe.  |||  Don't look now, but behind us is a guy who has the potential to break our hearts and plunge us into a pit of depression. Where?  Ooh, come to Momma.\n",
      "\n",
      "Why? Just wanna check my horoscope, see if it was right. Oh my God.  |||  Phoebe. Don't look now, but behind us is a guy who has the potential to break our hearts and plunge us into a pit of depression.\n",
      "\n",
      "Do you think they have yesterday's daily news? Why?  |||  Just wanna check my horoscope, see if it was right. Oh my God.\n",
      "\n",
      "Do you think they have yesterday's daily news? Why? Just wanna check my horoscope, see if it was right.  |||  Oh my God. Phoebe.\n",
      "\n",
      "Do you think they have yesterday's daily news?  |||  Why? Just wanna check my horoscope, see if it was right.\n",
      "\n",
      "Oh-ho yeah! A song with rhyming words. Oo, I never thought of that before. I like her. Why? Because she can sing and play guitar and do both at the same time?  |||  \n",
      "\n",
      "Wow! This girl is good. Oh-ho yeah! A song with rhyming words. Oo, I never thought of that before. I like her.  |||  Why? Because she can sing and play guitar and do both at the same time?\n",
      "\n",
      "Cause every time I see your face, I can't help but fall from grace. I know..... Wow! This girl is good. Oh-ho yeah! A song with rhyming words. Oo, I never thought of that before.  |||  I like her. Why? Because she can sing and play guitar and do both at the same time?\n",
      "\n",
      "Cause every time I see your face, I can't help but fall from grace. I know..... Wow! This girl is good.  |||  Oh-ho yeah! A song with rhyming words. Oo, I never thought of that before. I like her.\n",
      "\n",
      "Cause every time I see your face, I can't help but fall from grace. I know.....  |||  Wow! This girl is good. Oh-ho yeah! A song with rhyming words. Oo, I never thought of that before.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, a in df_train.iterrows():\n",
    "    if idx < 10:\n",
    "        print(f\"{a['hist_curr']}  |||  {a['next']}\\n\")\n",
    "    else:\n",
    "        # TODO qualcuno mi spieghi perchè con il break stampa solo la prima volta: iterrows non si rigenera?!\n",
    "        pass\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>trigger</th>\n",
       "      <th>hist_curr</th>\n",
       "      <th>next</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>surprise</td>\n",
       "      <td>0.0</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td></td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>So let's talk a little bit about your duties. ...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24390</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24389</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24391</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>So let's talk a little bit about your duties. ...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24395</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>My duties?  All right. Now you'll be heading a...</td>\n",
       "      <td></td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24392</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>My duties?  All right. Now you'll be heading a...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        emotion  trigger                                          hist_curr  \\\n",
       "864     neutral      0.0  also I was the point person on my company's tr...   \n",
       "868    surprise      0.0  That I did. That I did. So let's talk a little...   \n",
       "867     neutral      1.0  You must've had your hands full. That I did. T...   \n",
       "866     neutral      0.0  also I was the point person on my company's tr...   \n",
       "865     neutral      0.0  also I was the point person on my company's tr...   \n",
       "24390   neutral      0.0  also I was the point person on my company's tr...   \n",
       "24389   neutral      0.0  also I was the point person on my company's tr...   \n",
       "24391   neutral      0.0  also I was the point person on my company's tr...   \n",
       "24395   neutral      0.0  My duties?  All right. Now you'll be heading a...   \n",
       "24392   neutral      1.0  You must've had your hands full. That I did. T...   \n",
       "\n",
       "                                                    next    episode  \n",
       "864    You must've had your hands full. That I did. T...  episode_0  \n",
       "868                                                       episode_0  \n",
       "867                               My duties?  All right.  episode_0  \n",
       "866    So let's talk a little bit about your duties. ...  episode_0  \n",
       "865    That I did. That I did. So let's talk a little...  episode_0  \n",
       "24390  That I did. That I did. So let's talk a little...  episode_1  \n",
       "24389  You must've had your hands full. That I did. T...  episode_1  \n",
       "24391  So let's talk a little bit about your duties. ...  episode_1  \n",
       "24395                                                     episode_1  \n",
       "24392  My duties?  All right. Now you'll be heading a...  episode_1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>trigger</th>\n",
       "      <th>hist_curr</th>\n",
       "      <th>next</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>surprise</td>\n",
       "      <td>0.0</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td></td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>So let's talk a little bit about your duties. ...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24390</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24389</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24391</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>So let's talk a little bit about your duties. ...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24395</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>My duties?  All right. Now you'll be heading a...</td>\n",
       "      <td></td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24392</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>My duties?  All right. Now you'll be heading a...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        emotion  trigger                                          hist_curr  \\\n",
       "864     neutral      0.0  also I was the point person on my company's tr...   \n",
       "868    surprise      0.0  That I did. That I did. So let's talk a little...   \n",
       "867     neutral      1.0  You must've had your hands full. That I did. T...   \n",
       "866     neutral      0.0  also I was the point person on my company's tr...   \n",
       "865     neutral      0.0  also I was the point person on my company's tr...   \n",
       "24390   neutral      0.0  also I was the point person on my company's tr...   \n",
       "24389   neutral      0.0  also I was the point person on my company's tr...   \n",
       "24391   neutral      0.0  also I was the point person on my company's tr...   \n",
       "24395   neutral      0.0  My duties?  All right. Now you'll be heading a...   \n",
       "24392   neutral      1.0  You must've had your hands full. That I did. T...   \n",
       "\n",
       "                                                    next    episode  \n",
       "864    You must've had your hands full. That I did. T...  episode_0  \n",
       "868                                                       episode_0  \n",
       "867                               My duties?  All right.  episode_0  \n",
       "866    So let's talk a little bit about your duties. ...  episode_0  \n",
       "865    That I did. That I did. So let's talk a little...  episode_0  \n",
       "24390  That I did. That I did. So let's talk a little...  episode_1  \n",
       "24389  You must've had your hands full. That I did. T...  episode_1  \n",
       "24391  So let's talk a little bit about your duties. ...  episode_1  \n",
       "24395                                                     episode_1  \n",
       "24392  My duties?  All right. Now you'll be heading a...  episode_1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = explode_add_context(df_train_t, 2)\n",
    "dff.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>trigger</th>\n",
       "      <th>hist_curr</th>\n",
       "      <th>next</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>surprise</td>\n",
       "      <td>0.0</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td></td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>So let's talk a little bit about your duties. ...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24390</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        emotion  trigger                                          hist_curr  \\\n",
       "864     neutral      0.0  also I was the point person on my company's tr...   \n",
       "868    surprise      0.0  You must've had your hands full. That I did. T...   \n",
       "867     neutral      1.0  also I was the point person on my company's tr...   \n",
       "866     neutral      0.0  also I was the point person on my company's tr...   \n",
       "865     neutral      0.0  also I was the point person on my company's tr...   \n",
       "24390   neutral      0.0  also I was the point person on my company's tr...   \n",
       "\n",
       "                                                    next    episode  \n",
       "864    You must've had your hands full. That I did. T...  episode_0  \n",
       "868                                                       episode_0  \n",
       "867                               My duties?  All right.  episode_0  \n",
       "866    So let's talk a little bit about your duties. ...  episode_0  \n",
       "865    That I did. That I did. So let's talk a little...  episode_0  \n",
       "24390  That I did. That I did. So let's talk a little...  episode_1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = explode_add_context(df_train_t, 3)\n",
    "dff.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>trigger</th>\n",
       "      <th>hist_curr</th>\n",
       "      <th>next</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>You must've had your hands full. That I did. T...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>surprise</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td></td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>So let's talk a little bit about your duties. ...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td>episode_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24390</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>That I did. That I did. So let's talk a little...</td>\n",
       "      <td>episode_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        emotion  trigger                                          hist_curr  \\\n",
       "864     neutral      0.0  also I was the point person on my company's tr...   \n",
       "868    surprise      0.0  also I was the point person on my company's tr...   \n",
       "867     neutral      1.0  also I was the point person on my company's tr...   \n",
       "866     neutral      0.0  also I was the point person on my company's tr...   \n",
       "865     neutral      0.0  also I was the point person on my company's tr...   \n",
       "24390   neutral      0.0  also I was the point person on my company's tr...   \n",
       "\n",
       "                                                    next    episode  \n",
       "864    You must've had your hands full. That I did. T...  episode_0  \n",
       "868                                                       episode_0  \n",
       "867                               My duties?  All right.  episode_0  \n",
       "866    So let's talk a little bit about your duties. ...  episode_0  \n",
       "865    That I did. That I did. So let's talk a little...  episode_0  \n",
       "24390  That I did. That I did. So let's talk a little...  episode_1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = explode_add_context(df_train_t, 5)\n",
    "dff.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute F1 score for each flattened dialogue and return avg over dialogues\n",
    "def sequence_f1(\n",
    "    y_true: pd.DataFrame,\n",
    "    y_pred: np.ndarray,\n",
    "    target_column: str,\n",
    "    avg: bool = True,\n",
    ") -> Union[dict, float]:\n",
    "    assert len(y_pred) == len(y_true), \"y_pred and y_true must be of the same lenght\"\n",
    "    assert (\n",
    "        y_true[EPISODE].is_monotonic_increasing\n",
    "        or y_true[EPISODE].is_monotonic_decreasing\n",
    "    ), \"utterances must be sorted over the episodes\"\n",
    "\n",
    "    res = {}\n",
    "    start = 0\n",
    "    stop_incl = 0\n",
    "    for i in range(1, len(y_pred)):\n",
    "        if y_true[EPISODE][i - 1] != y_true[EPISODE][i]:\n",
    "            stop_incl = i - 1\n",
    "            f1 = f1_score(\n",
    "                y_true=y_true[target_column][start : stop_incl + 1].to_list(),\n",
    "                y_pred=y_pred[start : stop_incl + 1],\n",
    "                average=\"micro\",\n",
    "            )\n",
    "            res.update({y_true[EPISODE][start]: f1})\n",
    "            start = i\n",
    "\n",
    "    # np.std(list(res.values))\n",
    "    return res if not avg else np.average(list(res.values()))\n",
    "\n",
    "\n",
    "### Compute F1 score for the unrolled sequence\n",
    "def unrolled_f1(\n",
    "    y_true: pd.DataFrame,\n",
    "    y_pred: np.ndarray,\n",
    "    target_column: str,\n",
    ") -> float:\n",
    "    return f1_score(y_true[target_column].to_list(), y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create baseline models\n",
    "\n",
    "\n",
    "# TODO do we still need the class?\n",
    "class SequenceDummyClassifier(DummyClassifier):\n",
    "    def __init__(self, strategy: str, seed: int = 42) -> None:\n",
    "        self.seed = seed\n",
    "        if not strategy.lower() in (\"random\", \"majority\"):\n",
    "            raise ValueError(\"strategy must be in [random, majority]\")\n",
    "        sklearn_strategy = \"uniform\" if strategy == \"random\" else \"most_frequent\"\n",
    "        super().__init__(strategy=sklearn_strategy, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_f1(emotion_Random) : 0.44657433160540777\n",
      "unrolled_f1(emotion_Random) : 0.4330935251798561\n",
      "sequence_f1(trigger_Random) : 0.6522845341422358\n",
      "unrolled_f1(trigger_Random) : 0.6515107913669065\n",
      "sequence_f1(emotion_Majority) : 0.44657433160540777\n",
      "unrolled_f1(emotion_Majority) : 0.4330935251798561\n",
      "sequence_f1(trigger_Majority) : 0.6522845341422358\n",
      "unrolled_f1(trigger_Majority) : 0.6515107913669065\n"
     ]
    }
   ],
   "source": [
    "def experiment_baseline(\n",
    "    df_train: pd.DataFrame,\n",
    "    df_test: pd.DataFrame,\n",
    "    seed: int = 42,\n",
    ") -> dict:\n",
    "\n",
    "    baseline_f1s = {}\n",
    "    baseline_results = {}\n",
    "\n",
    "    for strategy in (\"Random\", \"Majority\"):\n",
    "        for target in (\"emotion\", \"trigger\"):\n",
    "            clf = SequenceDummyClassifier(strategy=strategy, seed=seed)\n",
    "            clf.fit(X=df_train[\"hist_curr\"], y=df_train[target])\n",
    "\n",
    "            res = clf.predict(X=df_test[\"hist_curr\"])\n",
    "            baseline_results.update({f\"{target}_{strategy}\": res})\n",
    "\n",
    "            seq_f1 = sequence_f1(y_true=df_test, y_pred=res, target_column=target)\n",
    "            baseline_f1s.update({f\"sequence_f1({target}_{strategy})\": seq_f1})\n",
    "\n",
    "            unr_f1 = unrolled_f1(y_true=df_test, y_pred=res, target_column=target)\n",
    "            baseline_f1s.update({f\"unrolled_f1({target}_{strategy})\": unr_f1})\n",
    "\n",
    "    return baseline_f1s, baseline_results\n",
    "\n",
    "\n",
    "f1s, results = experiment_baseline(df_train, df_test)\n",
    "for k, v in f1s.items():\n",
    "    print(f\"{k} : {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset.from_pandas(df_train)\n",
    "ds_val = Dataset.from_pandas(df_val)\n",
    "ds_test = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove\n",
    "def encode(tokenizer, df, labels_emo, labels_tri):\n",
    "    \"\"\"\n",
    "    Encodes the dataset according to the BERT specifications.\n",
    "    The method encodes the data in the following way:\n",
    "      [CLS] current [SEP] future [SEP]\n",
    "      where -current- is the concatenation of history+utterance\n",
    "      and -future- is the sentence following the utterance\n",
    "    \"\"\"\n",
    "    # concatenate the history and the utterance\n",
    "    his_cur = df[\"history\"].str.cat(df[\"utterance\"])\n",
    "    # encoding version without future feature\n",
    "    \"\"\"encodings = tokenizer(list(df['history']),\n",
    "                        list(df['utterance']),\n",
    "                          padding=True,\n",
    "                          truncation=True,\n",
    "                          max_length = 512,\n",
    "                          )\"\"\"\n",
    "    encodings = tokenizer(\n",
    "        list(his_cur),\n",
    "        list(df[\"future\"]),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "    input_ids, input_attention_mask = (\n",
    "        encodings[\"input_ids\"],\n",
    "        encodings[\"attention_mask\"],\n",
    "    )\n",
    "    print(f\"input shape: {np.shape(input_ids)}\")\n",
    "    encodings.update({\"labels_emo\": torch.LongTensor(labels_emo.values)})\n",
    "    labels_tri = np.expand_dims(labels_tri.values, axis=1)\n",
    "    encodings.update({\"labels_tri\": torch.FloatTensor(labels_tri)})\n",
    "    encodings.pop(\"token_type_ids\")\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(ds_row, tokenizer):\n",
    "    if type(ds_row[\"emotion\"]) != str:  ### batchsize > 1\n",
    "        emotion_encoding = []\n",
    "        emotion_encoding = [emotion_mapping[e] for e in ds_row[\"emotion\"]]\n",
    "    else:  ### batchsize == 1\n",
    "        emotion_encoding = emotion_mapping[ds_row[\"emotion\"]]\n",
    "\n",
    "    encoded_ds_row = {\n",
    "        \"input_ids\": [],\n",
    "        \"token_type_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"emotions\": emotion_encoding,\n",
    "        \"triggers\": ds_row[\n",
    "            \"trigger\"\n",
    "        ],  # TODO non è necessario metterlo in un tensore, ci pensa ds.set_format(type='torch')\n",
    "    }\n",
    "\n",
    "    tokenized_context = tokenizer(\n",
    "        ds_row[\"hist_curr\"],\n",
    "        ds_row[\"next\"] if ds_row[\"next\"] != [] else None,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=tokenizer.model_max_length // 2,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    encoded_ds_row[\"input_ids\"] = tokenized_context[\"input_ids\"]\n",
    "    encoded_ds_row[\"token_type_ids\"] = tokenized_context[\"token_type_ids\"]\n",
    "\n",
    "    encoded_ds_row[\"attention_mask\"] = tokenized_context[\"attention_mask\"]\n",
    "\n",
    "    return encoded_ds_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f645ebba2347198ea1143247d2b466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9412babd0f74804be4ff08918dd551b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "tensor([[  101,  2036,  1045,  2001,  1996,  2391,  2711,  2006,  2026,  2194,\n",
      "          1005,  1055,  6653,  2013,  1996,  1047,  2140,  1011,  1019,  2000,\n",
      "         24665,  1011,  1020,  2291,  1012,  2017,  2442,  1005,  2310,  2018,\n",
      "          2115,  2398,  2440,  1012,  2008,  1045,  2106,  1012,  2008,  1045,\n",
      "          2106,  1012,   102,  2061,  2292,  1005,  1055,  2831,  1037,  2210,\n",
      "          2978,  2055,  2115,  5704,  1012,  2026,  5704,  1029,  2035,  2157,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]])\n",
      "1\n",
      "256\n",
      "neutral\n",
      "tensor([  101,  2036,  1045,  2001,  1996,  2391,  2711,  2006,  2026,  2194,\n",
      "         1005,  1055,  6653,  2013,  1996,  1047,  2140,  1011,  1019,  2000,\n",
      "        24665,  1011,  1020,  2291,  1012,  2017,  2442,  1005,  2310,  2018,\n",
      "         2115,  2398,  2440,  1012,  2008,  1045,  2106,  1012,  2008,  1045,\n",
      "         2106,  1012,   102,  2061,  2292,  1005,  1055,  2831,  1037,  2210,\n",
      "         2978,  2055,  2115,  5704,  1012,  2026,  5704,  1029,  2035,  2157,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n",
      "256\n",
      "[CLS] also i was the point person on my company ' s transition from the kl - 5 to gr - 6 system . you must ' ve had your hands full . that i did . that i did . [SEP] so let ' s talk a little bit about your duties . my duties ? all right . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS] also i was the point person on my company ' s transition from the kl - 5 to gr - 6 system . you must ' ve had your hands full . that i did . that i did . [SEP] so let ' s talk a little bit about your duties . my duties ? all right . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "{'emotion': 'neutral', 'trigger': 0.0, 'hist_curr': \"also I was the point person on my company's transition from the KL-5 to GR-6 system. You must've had your hands full. That I did. That I did.\", 'next': \"So let's talk a little bit about your duties. My duties?  All right.\", 'episode': 'episode_0', '__index_level_0__': 866}\n"
     ]
    }
   ],
   "source": [
    "### TEST\n",
    "ds_short = Dataset.from_pandas(df_train.iloc[0:4])\n",
    "ds_short_tokenized = ds_short.map(\n",
    "    function=tokenize,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    batched=False,\n",
    "    remove_columns=[\"hist_curr\", \"next\"],\n",
    ")\n",
    "ds_short_tokenized_batched = ds_short.map(\n",
    "    function=tokenize,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    batched=True,\n",
    "    remove_columns=[\"hist_curr\", \"next\"],\n",
    ")\n",
    "\n",
    "idx = 3\n",
    "\n",
    "ds_short_tokenized.set_format(type=\"torch\")\n",
    "ds_short_tokenized_batched.set_format(type=\"torch\")\n",
    "\n",
    "ids = ds_short_tokenized[\"input_ids\"][idx]\n",
    "ids_batch = ds_short_tokenized_batched[\"input_ids\"][idx]\n",
    "print(ds_short_tokenized[\"emotion\"][idx])\n",
    "print(ids)\n",
    "print(len(ids))\n",
    "print(len(ids[0]))\n",
    "print(ds_short_tokenized_batched[\"emotion\"][idx])\n",
    "print(ids_batch)\n",
    "print(len(ids_batch))\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids[0])\n",
    "tokens_batched = tokenizer.convert_ids_to_tokens(ids_batch)\n",
    "original_string = tokenizer.convert_tokens_to_string(tokens)\n",
    "original_string_batched = tokenizer.convert_tokens_to_string(tokens_batched)\n",
    "print(original_string)\n",
    "print(original_string_batched)\n",
    "print(ds_short[idx])\n",
    "\n",
    "# OSSERVAZIONI:\n",
    "# ds.set_format(type='torch') mette trigger ed emotion dentro a dei tensori e fa qualcosa a input_ids per cui viene stampato come matrice e non come riga\n",
    "# a prescindere da set_format:  input_ids è una [[]] se tokeniziamo senza batch, è una [] se tokenizziamo con il batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove\n",
    "def encode_emotion(ds_row, mapping):\n",
    "    if type(ds_row[\"emotion\"]) != str:  ### batchsize > 1\n",
    "        emotion_encoding = []\n",
    "        emotion_encoding = [mapping[e] for e in ds_row[\"emotion\"]]\n",
    "    else:  ### batchsize == 1\n",
    "        emotion_encoding = mapping[ds_row[\"emotion\"]]\n",
    "    ds_row[\"emotion\"] = emotion_encoding\n",
    "    return ds_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73262e00fc14684bb9b5f4a54e2c775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28034 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600cfed7514f4812a8aefb34aae8e711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3475 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dcf77c5ae74e96a2781d84996123c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3491 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Apply tokenization\n",
    "\n",
    "batched = True\n",
    "cols_to_drop = [\"hist_curr\", \"next\"]\n",
    "\n",
    "# TODO remove\n",
    "# ds_train = ds_train.map(\n",
    "#    function=encode_emotion,\n",
    "#    fn_kwargs={\"mapping\": emotion_mapping},\n",
    "#    batched=batched,\n",
    "# )\n",
    "ds_train_tokenized = ds_train.map(\n",
    "    function=tokenize,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    batched=batched,\n",
    "    remove_columns=cols_to_drop,\n",
    ")\n",
    "ds_train_tokenized.set_format(type=\"torch\")\n",
    "\n",
    "ds_test_tokenized = ds_test.map(\n",
    "    function=tokenize,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    batched=batched,\n",
    "    remove_columns=cols_to_drop,\n",
    ")\n",
    "ds_test_tokenized.set_format(type=\"torch\")\n",
    "\n",
    "ds_val_tokenized = ds_val.map(\n",
    "    function=tokenize,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    batched=batched,\n",
    "    remove_columns=cols_to_drop,\n",
    ")\n",
    "ds_val_tokenized.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "also I was the point person on my company's transition from the KL-5 to GR-6 system.You must've had your hands full. That I did. That I did.\n",
      "[CLS] also i was the point person on my company ' s transition from the kl - 5 to gr - 6 system . [SEP] you must ' ve had your hands full . that i did . that i did . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "### Tokenization test\n",
    "tokens = tokenizer.convert_ids_to_tokens(ds_train_tokenized[\"input_ids\"][0])\n",
    "string = tokenizer.convert_tokens_to_string(tokens)\n",
    "original_string = ds_train[\"hist_curr\"][0] + ds_train[\"next\"][0]\n",
    "print(original_string)\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class weighting algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(df: pd.Series) -> torch.tensor:\n",
    "    labels, n_ones = np.unique(df.to_numpy, return_counts=True)\n",
    "    l = len(df)\n",
    "    n_zeroes = np.array([l - n for n in n_ones])\n",
    "\n",
    "    weights = np.empty_like(n_ones)\n",
    "    for class_num, (ones, zeroes) in enumerate(zip(n_ones, n_zeroes)):\n",
    "        # TODO choose one\n",
    "        weights[class_num] = zeroes / (ones + 1e-4)\n",
    "        # weights[class_num] = np.sqrt(zeroes / (ones + 1e-4))\n",
    "\n",
    "    print(f\"weigts = {weights}\")\n",
    "    return torch.as_tensor(weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, num_emotions=7):\n",
    "        super(BERTClass, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        # self.lstm = torch.nn.LSTM()\n",
    "        # classifiers\n",
    "        self.l_emotions = torch.nn.Linear(self.bert.config.hidden_size, num_emotions)\n",
    "        self.l_triggers = torch.nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        output = output.pooler_output\n",
    "        output_emotions = self.dropout(output)\n",
    "        output_triggers = self.dropout(output)\n",
    "\n",
    "        # output_triggers = self.lstm(output_triggers)\n",
    "\n",
    "        output_emotions = self.l_emotions(output_emotions)\n",
    "        output_triggers = torch.squeeze(self.l_triggers(output_triggers))\n",
    "\n",
    "        return output_emotions, output_triggers\n",
    "\n",
    "    def freeze_params(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_emotions = len(uniq_emotions)\n",
    "\n",
    "model_frozen = BERTClass(num_emotions)\n",
    "model_full = BERTClass(num_emotions)\n",
    "\n",
    "model_frozen.to(device)\n",
    "model_full.to(device)\n",
    "model_frozen.freeze_params()\n",
    "\n",
    "# Verifying that the params are actually frozen\n",
    "# for name, param in model_frozen.named_parameters():\n",
    "#     print(name, param.requires_grad)\n",
    "#\n",
    "# for name, param in model_full.named_parameters():\n",
    "#     print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_full, model_frozen]\n",
    "num_epochs = 5\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "for model in model_list:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "\n",
    "    # Tokenizer initiation\n",
    "    # TODO Check tokenizer parameters\n",
    "    # TODO A Dataloader seems to be commonly used for this use cases\n",
    "    # encoding = tokenizer(df_train, truncation=False, padding='max_length', return_tensors='pt')\n",
    "    # input_ids = encoding['input_ids']\n",
    "    # attention_mask = encoding['attention_mask']\n",
    "\n",
    "    # Training loop\n",
    "    # for epoch in range(num_epochs):\n",
    "    #\n",
    "    #    for idx in range(len(df_test)):\n",
    "\n",
    "    #        text = df_train[idx].drop(TRIGGERS)\n",
    "    #        label = df_train[idx][TRIGGERS]\n",
    "\n",
    "    #        optimizer.zero_grad()\n",
    "\n",
    "    #        logits = model(batch_data)\n",
    "    #        loss = loss_fn(logits, batch_labels)\n",
    "    #        loss.backward()\n",
    "    #        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs_emotions, outputs_triggers, emotions_labels, triggers_labels):\n",
    "    L1 = torch.nn.CrossEntropyLoss()\n",
    "    L2 = torch.nn.BCEWithLogitsLoss()\n",
    "    # print(f\"output_triggers shape = {outputs_triggers.shape}\")\n",
    "    # print(f\"triggers labels shape {triggers_labels.shape}\")\n",
    "    return L1(outputs_emotions, emotions_labels) + L2(outputs_triggers, triggers_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training of the model\n",
    "def train_model(train_dl, model, optimizer):\n",
    "    losses = []\n",
    "    correct_predictions_emotions = 0\n",
    "    correct_predictions_triggers = 0\n",
    "    num_samples_emotions = 0\n",
    "    num_samples_triggers = 0\n",
    "\n",
    "    ### activate dropout, batch norm\n",
    "    model.train()\n",
    "\n",
    "    ### initialize progress bar\n",
    "    batches = tq.tqdm(\n",
    "        enumerate(train_dl), total=len(train_dl), leave=True, colour=\"steelblue\"\n",
    "    )\n",
    "\n",
    "    for batch_idx, data in batches:\n",
    "        ids = data[\"input_ids\"].to(device, dtype=torch.long)\n",
    "        mask = data[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "        token_type_ids = data[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "        emotions_labels = data[\"emotions\"].to(device, dtype=torch.float)\n",
    "        triggers_labels = data[\"triggers\"].to(device, dtype=torch.float)\n",
    "\n",
    "        ### Forward pass\n",
    "        outputs_emotions, outputs_triggers = model(ids, mask, token_type_ids)\n",
    "\n",
    "        loss = loss_fn(\n",
    "            outputs_emotions, outputs_triggers, emotions_labels, triggers_labels\n",
    "        )\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        ### apply thresh 0.5\n",
    "        outputs_emotions = (\n",
    "            torch.sigmoid(outputs_emotions).cpu().detach().numpy().round()\n",
    "        )\n",
    "        outputs_triggers = (\n",
    "            torch.sigmoid(outputs_triggers).cpu().detach().numpy().round()\n",
    "        )\n",
    "\n",
    "        emotions_labels = emotions_labels.cpu().detach().numpy()\n",
    "        triggers_labels = triggers_labels.cpu().detach().numpy()\n",
    "\n",
    "        correct_predictions_emotions += np.sum(outputs_emotions == emotions_labels)\n",
    "        correct_predictions_triggers += np.sum(outputs_triggers == triggers_labels)\n",
    "\n",
    "        num_samples_emotions += emotions_labels.size\n",
    "        num_samples_triggers += triggers_labels.size\n",
    "\n",
    "        ### Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        ### Grad descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        ### Update progress bar\n",
    "        batches.set_description(f\"\")\n",
    "        batches.set_postfix(batch_loss=loss)\n",
    "\n",
    "    # Si potrebbe fare una singola accuracy come media delle due, magari fuori dal training\n",
    "    accuracy_emotions = float(correct_predictions_emotions) / num_samples_emotions\n",
    "    accuracy_triggers = float(correct_predictions_triggers) / num_samples_triggers\n",
    "\n",
    "    return model, accuracy_emotions, accuracy_triggers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(validation_dl, model):\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    num_categories = next(iter(validation_dl))[\"labels\"].shape[1]\n",
    "\n",
    "    ### accumulate data over each batch to compute the f1\n",
    "    true_positives = np.array([0 for _ in range(num_categories)])\n",
    "    false_positives = np.array([0 for _ in range(num_categories)])\n",
    "    false_negatives = np.array([0 for _ in range(num_categories)])\n",
    "\n",
    "    ### turn off dropout, fix batch norm\n",
    "    model.eval()\n",
    "\n",
    "    ### show progress bar\n",
    "    batches = tq.tqdm(\n",
    "        enumerate(validation_dl),\n",
    "        total=len(validation_dl),\n",
    "        leave=True,\n",
    "        colour=\"steelblue\",\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in batches:\n",
    "            ids = data[\"input_ids\"].to(device, dtype=torch.long)\n",
    "            mask = data[\"attention_mask\"].to(device, dtype=torch.long)\n",
    "            token_type_ids = data[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "            emotions_labels = data[\"emotions\"].to(device, dtype=torch.float)\n",
    "            triggers_labels = data[\"triggers\"].to(device, dtype=torch.float)\n",
    "            outputs_emotions, outputs_triggers = model(ids, mask, token_type_ids)\n",
    "\n",
    "            loss = loss_fn(\n",
    "                outputs_emotions, outputs_triggers, emotions_labels, triggers_labels\n",
    "            )\n",
    "            losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "            ### validation accuracy\n",
    "            ### training sigmoid is in BCEWithLogitsLoss\n",
    "            outputs_emotions = (\n",
    "                torch.sigmoid(outputs_emotions).cpu().detach().numpy().round()\n",
    "            )\n",
    "            outputs_triggers = (\n",
    "                torch.sigmoid(outputs_triggers).cpu().detach().numpy().round()\n",
    "            )\n",
    "\n",
    "            emotions_labels = emotions_labels.cpu().detach().numpy()\n",
    "            triggers_labels = triggers_labels.cpu().detach().numpy()\n",
    "            correct_predictions_emotions += np.sum(outputs_emotions == emotions_labels)\n",
    "            correct_predictions_triggers += np.sum(outputs_triggers == triggers_labels)\n",
    "\n",
    "            num_samples_emotions += emotions_labels.size\n",
    "            num_samples_triggers += triggers_labels.size\n",
    "\n",
    "        accuracy_emotions = float(correct_predictions_emotions) / num_samples_emotions\n",
    "        accuracy_triggers = float(correct_predictions_triggers) / num_samples_triggers\n",
    "        # precision = true_positives / (true_positives + false_positives)\n",
    "        # recall = true_positives / (true_positives + false_negatives)\n",
    "        # f1_per_cat = 2 * (precision * recall) / (precision + recall)\n",
    "        # f1_overall = np.mean(f1_per_cat)\n",
    "\n",
    "    return accuracy_emotions, accuracy_triggers, losses  # , f1_overall, f1_per_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(\n",
    "    train_dl,\n",
    "    validation_dl,\n",
    "    model,\n",
    "    optimizer,\n",
    "    n_epochs=1,\n",
    "    save_name=\"0\",\n",
    "    train_model_f=train_model,\n",
    "    eval_model_f=eval_model,\n",
    "):\n",
    "    model_folder = Path.cwd().joinpath(\"models\")\n",
    "    if not model_folder.exists():\n",
    "        model_folder.mkdir(parents=True)\n",
    "\n",
    "    history = {}\n",
    "    best_f1 = 0\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "        model, accuracy_emotions, accuracy_triggers, train_loss = train_model_f(\n",
    "            train_dl, model, optimizer\n",
    "        )\n",
    "        val_accuracy_emotions, val_accuracy_triggers, val_loss = eval_model_f(\n",
    "            validation_dl, model\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"train_loss={np.mean(train_loss):.4f}, val_loss={np.mean(val_loss):.4f}, \"\n",
    "            f\"train_acc_emo={accuracy_emotions:.4f}, train_acc_emo={accuracy_triggers:.4f},\"\n",
    "            f\"val_acc_emo={val_accuracy_emotions:.4f}, val_acc_tri={val_accuracy_triggers:.4f}, \"\n",
    "        )\n",
    "\n",
    "        history.update({\"train_acc_emo\": accuracy_emotions})\n",
    "        history.update({\"train_acc_tri\": accuracy_triggers})\n",
    "        history.update({\"train_losses\": train_loss})\n",
    "        history.update({\"val_acc_emo\": val_accuracy_emotions})\n",
    "        history.update({\"val_acc_emo\": val_accuracy_triggers})\n",
    "        history.update({\"val_losses\": val_loss})\n",
    "        # history.update({\"f1_overall\": f1_overall})\n",
    "        # history.update({\"f1_per_cat\": f1_per_cat})\n",
    "\n",
    "        ### save the best model\n",
    "        # if f1_overall > best_f1:\n",
    "        #   torch.save(\n",
    "        #      model.state_dict(),\n",
    "        #      Path.joinpath(model_folder, f\"model_{save_name}.bin\"),\n",
    "        # )\n",
    "        # best_f1 = f1_overall\n",
    "\n",
    "    return history  # (history[\"f1_overall\"], history[\"f1_per_cat\"], history[\"train_losses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(tokenized_datasets, batch_size):\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        tokenized_datasets[\"train\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    validation_dl = torch.utils.data.DataLoader(\n",
    "        tokenized_datasets[\"validation\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    test_dl = torch.utils.data.DataLoader(\n",
    "        tokenized_datasets[\"test\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    return train_dl, validation_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    ds_train_tokenized,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "validation_dl = torch.utils.data.DataLoader(\n",
    "    ds_val_tokenized,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Custom loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df708f98f6a442678e50a3759724fcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14017 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Reshape the target tensor to have the same size as the input tensor\u001b[39;00m\n\u001b[1;32m     11\u001b[0m target_size \u001b[38;5;241m=\u001b[39m history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msize()\n",
      "Cell \u001b[0;32mIn[46], line 20\u001b[0m, in \u001b[0;36mtrain_eval\u001b[0;34m(train_dl, validation_dl, model, optimizer, n_epochs, save_name, train_model_f, eval_model_f)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     model, accuracy_emotions, accuracy_triggers, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_f\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     val_accuracy_emotions, val_accuracy_triggers, val_loss \u001b[38;5;241m=\u001b[39m eval_model_f(\n\u001b[1;32m     24\u001b[0m         validation_dl, model\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(train_loss)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(val_loss)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc_emo=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_emotions\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train_acc_emo=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_triggers\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc_emo=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy_emotions\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_acc_tri=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy_triggers\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[44], line 25\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(train_dl, model, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m triggers_labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtriggers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m### Forward pass\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m outputs_emotions, outputs_triggers \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(\n\u001b[1;32m     28\u001b[0m     outputs_emotions, outputs_triggers, emotions_labels, triggers_labels\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 14\u001b[0m, in \u001b[0;36mBERTClass.forward\u001b[0;34m(self, ids, mask, token_type_ids)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, ids, mask, token_type_ids):\n\u001b[0;32m---> 14\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mpooler_output\n\u001b[1;32m     17\u001b[0m     output_emotions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(output)\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1012\u001b[0m )\n\u001b[0;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    598\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         output_attentions,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:286\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    278\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    285\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 286\u001b[0m     mixed_query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# and values come from an encoder; the attention mask needs to be\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/NLP_PROJECT/NLP-project/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = train_eval(\n",
    "    train_dl,\n",
    "    validation_dl,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    save_name=f\"test_model\",\n",
    ")\n",
    "\n",
    "# Reshape the target tensor to have the same size as the input tensor\n",
    "target_size = history[\"train_losses\"].size()\n",
    "input_size = history[\"train_acc_emo\"].size()\n",
    "if target_size != input_size:\n",
    "    history[\"train_losses\"] = history[\"train_losses\"].view(*input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor [[utt + pad], [utt + pad], [utt + pad]]\n",
    "tensor [CLS + utt + SEP + utt + SEP + utt + SEP + pad]\n",
    "[ tensor[cls utt padd] tensor [cls utt padd]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training con Classe Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTrainer(Trainer):\n",
    "    def __init__(self, model, training_args, train_ds, eval_ds, metrics):\n",
    "        super().__init__(model, training_args, train_ds, eval_ds, metrics)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        emotions_labels = inputs[\"emotions\"]\n",
    "        triggers_labels = inputs[\"triggers\"]\n",
    "        output_emotions, output_triggers = model(ids=ids, mask=mask)\n",
    "\n",
    "        custom_loss = self.loss_fn(\n",
    "            output_emotions, output_triggers, emotions_labels, triggers_labels\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            (custom_loss, output_emotions, output_triggers)\n",
    "            if return_outputs\n",
    "            else custom_loss\n",
    "        )\n",
    "\n",
    "    def loss_fn(outputs_emotions, outputs_triggers, emotions_labels, triggers_labels):\n",
    "        return torch.nn.CrossEntropyLoss(\n",
    "            outputs_emotions, emotions_labels\n",
    "        ) + torch.nn.BCELoss(outputs_triggers, triggers_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"\\\\test\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    # evaluate_during_training=True,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=8,\n",
    "    # seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_full,\n",
    "    args=training_args,\n",
    "    # data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    train_dataset=ds_train_tokenized,\n",
    "    # eval_dataset=ds_val_tokenized,\n",
    "    compute_metrics=sequence_f1,\n",
    "    # tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
